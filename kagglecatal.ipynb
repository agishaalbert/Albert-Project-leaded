{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ttach","metadata":{"id":"HqyOPyM0B1qn","outputId":"ae0d0cc5-92f6-4e5d-ade1-9dbb00c5c79d","execution":{"iopub.status.busy":"2022-04-17T09:13:06.001630Z","iopub.execute_input":"2022-04-17T09:13:06.001986Z","iopub.status.idle":"2022-04-17T09:13:14.814822Z","shell.execute_reply.started":"2022-04-17T09:13:06.001916Z","shell.execute_reply":"2022-04-17T09:13:14.813938Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install git+https://github.com/gbaydin/hypergradient-descent.git","metadata":{"id":"NOu9AZqjB1qq","outputId":"31f1256e-1622-44cf-95f0-181cf4c4a782","execution":{"iopub.status.busy":"2022-04-17T09:13:14.820974Z","iopub.execute_input":"2022-04-17T09:13:14.821243Z","iopub.status.idle":"2022-04-17T09:13:27.388875Z","shell.execute_reply.started":"2022-04-17T09:13:14.821205Z","shell.execute_reply":"2022-04-17T09:13:27.388025Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!pip install pretrainedmodels","metadata":{"id":"066bMesyB1qr","outputId":"f389ea67-1bcc-4da3-ff66-83080eb2bd49","execution":{"iopub.status.busy":"2022-04-17T09:13:27.392405Z","iopub.execute_input":"2022-04-17T09:13:27.392620Z","iopub.status.idle":"2022-04-17T09:13:36.106605Z","shell.execute_reply.started":"2022-04-17T09:13:27.392592Z","shell.execute_reply":"2022-04-17T09:13:36.105769Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install efficientnet_pytorch","metadata":{"id":"KsTII-SICTYo","outputId":"267722db-b8c1-4f8f-ab13-571f111c71c6","execution":{"iopub.status.busy":"2022-04-17T09:13:36.110769Z","iopub.execute_input":"2022-04-17T09:13:36.110992Z","iopub.status.idle":"2022-04-17T09:13:45.149664Z","shell.execute_reply.started":"2022-04-17T09:13:36.110965Z","shell.execute_reply":"2022-04-17T09:13:45.148697Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#Imports\nimport os\nimport sys\nimport glob\nimport torch\nimport torchvision\n\nimport numpy    as np\nimport datetime as dt\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot   as plt\n\nfrom PIL               import Image\nfrom torch.utils.data  import Dataset\nfrom torch.autograd    import Variable\nfrom torch.optim       import lr_scheduler\n\nfrom torch.utils.data  import Dataset, DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torchvision       import transforms, datasets, models\nfrom os                import listdir, makedirs, getcwd, remove\nfrom os.path           import isfile, join, abspath, exists, isdir, expanduser\n\n\nimport pandas as pd\n\nfrom hypergrad import SGDHD, AdamHD\n\nimport pretrainedmodels\n\nfrom efficientnet_pytorch import EfficientNet\n\nimport ttach as tta\n\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","id":"i3LoBOuBB1qr","execution":{"iopub.status.busy":"2022-04-17T09:13:45.154475Z","iopub.execute_input":"2022-04-17T09:13:45.156425Z","iopub.status.idle":"2022-04-17T09:13:46.833405Z","shell.execute_reply.started":"2022-04-17T09:13:45.156385Z","shell.execute_reply":"2022-04-17T09:13:46.832670Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"NAME = \"SUBMISSION2\"\n\nMODEL_NAME1 = 'se_resnext101_32x4d' # could be fbresnet152 or inceptionresnetv2\nMODEL_NAME2 = 'efficientnet-b0'\nDIM_1 = 550\nDIM_2 = 500\nDIM_TEST_1 = 550\nDIM_TEST_2 = 500\n\nBATCH_SIZE = 8\n\nNUM_EPOCHS1 = 20\n\nrandom_seed = 42\nshuffle_dataset = True\nvalidation_split = .1","metadata":{"id":"5HETNaJ5B1qs","execution":{"iopub.status.busy":"2022-04-17T09:13:46.834673Z","iopub.execute_input":"2022-04-17T09:13:46.834914Z","iopub.status.idle":"2022-04-17T09:13:46.841686Z","shell.execute_reply.started":"2022-04-17T09:13:46.834881Z","shell.execute_reply":"2022-04-17T09:13:46.841012Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Device configuration\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"vUQi3oSrB1qt","execution":{"iopub.status.busy":"2022-04-17T09:13:46.842746Z","iopub.execute_input":"2022-04-17T09:13:46.845894Z","iopub.status.idle":"2022-04-17T09:13:46.871093Z","shell.execute_reply.started":"2022-04-17T09:13:46.845857Z","shell.execute_reply":"2022-04-17T09:13:46.870399Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data_path = \"../input/ammi-2022-convnets/\"\ntrain_path = join(data_path, \"train/train\")\ntest_path = join(data_path,\"test/test\")\nextraimage_path = join(data_path, \"extraimages/extraimages\")","metadata":{"id":"eCENs2WvB1qt","execution":{"iopub.status.busy":"2022-04-17T09:13:46.872509Z","iopub.execute_input":"2022-04-17T09:13:46.872817Z","iopub.status.idle":"2022-04-17T09:13:46.880238Z","shell.execute_reply.started":"2022-04-17T09:13:46.872782Z","shell.execute_reply":"2022-04-17T09:13:46.879524Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"a6WaJB9NCwGG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"0y8NQTDRCweN","outputId":"05bd8939-f799-46ad-f647-6d660c5c3a03"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"U3O3O8qqCggO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transformations for both the training and testing data\nmean=[0.485, 0.456, 0.406]\nstd=[0.229, 0.224, 0.225]\n\n# Do data transforms here, Try many others\ntrain_transforms = transforms.Compose([transforms.RandomRotation(30),\n                                       transforms.Resize(DIM_1),\n                                       transforms.RandomCrop(DIM_2),\n                                       transforms.RandomHorizontalFlip(0.3),\n                                       transforms.RandomVerticalFlip(0.3),\n                                       transforms.ToTensor(),\n                                       transforms.RandomErasing(0.1),\n                                       transforms.Normalize(mean=mean, std=std)])\n\ntest_transforms = transforms.Compose([ transforms.Resize(DIM_TEST_1),\n                                      transforms.CenterCrop(DIM_TEST_1),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize(mean=mean, std=std)])","metadata":{"id":"jXMr-my0B1qu","execution":{"iopub.status.busy":"2022-04-17T09:13:46.881422Z","iopub.execute_input":"2022-04-17T09:13:46.881764Z","iopub.status.idle":"2022-04-17T09:13:46.891159Z","shell.execute_reply.started":"2022-04-17T09:13:46.881726Z","shell.execute_reply":"2022-04-17T09:13:46.890518Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class CassavaDataset(Dataset):\n    def __init__(self, path, dim, transform=None):\n        self.classes = os.listdir(path)\n        self.path = [f\"{path}/{className}\" for className in self.classes]\n        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n        self.transform = transform\n        self.dim = dim\n\n        self.targets = []\n        \n\n        files = []\n        for i, className in enumerate(self.classes):\n            for fileName in self.file_list[i]:\n                files.append([i, className, fileName])\n                self.targets.append(i)\n                \n        self.file_list = files\n        files = None\n\n    def __len__(self):\n        return len(self.file_list)\n\n    def __getitem__(self, idx):\n        fileName = self.file_list[idx][2]\n        classCategory = self.file_list[idx][0]\n        im = Image.open(fileName)\n        if self.transform:\n            im = self.transform(im)\n            \n        return im.view(3, self.dim, self.dim), classCategory\n\nclass CassavaTestDataset(Dataset):\n    def __init__(self, path, dim, transform=None):\n        self.classes = os.listdir(path)\n        self.path = [f\"{path}/{className}\" for className in self.classes]\n        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n        self.transform = transform\n        self.indices = []\n        self.dim=dim\n\n        files = []\n        for i, className in enumerate(self.classes):\n            for fileName in self.file_list[i]:\n                files.append([i, className, fileName])\n                self.indices.append(fileName.split(\"/\")[-1])\n        self.file_list = files\n        files = None\n\n    def __len__(self):\n        return len(self.file_list)\n\n    def __getitem__(self, idx):\n        fileName = self.file_list[idx][2]\n        index = self.file_list[idx][2]\n        im = Image.open(fileName)\n        if self.transform:\n            im = self.transform(im)\n            \n        return im.view(3, self.dim, self.dim), index\n\ntrain_data = CassavaDataset(train_path, dim=DIM_2, transform=train_transforms)\ntest_data = CassavaTestDataset(test_path, dim=DIM_TEST_1, transform=test_transforms)","metadata":{"id":"9bX5DFgLB1qu","execution":{"iopub.status.busy":"2022-04-17T09:13:46.892541Z","iopub.execute_input":"2022-04-17T09:13:46.892795Z","iopub.status.idle":"2022-04-17T09:13:46.949689Z","shell.execute_reply.started":"2022-04-17T09:13:46.892761Z","shell.execute_reply":"2022-04-17T09:13:46.949073Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_data.classes","metadata":{"id":"QVyNneaIB1qv","outputId":"df4903c3-1fac-4e47-9ebb-8d3788f7caf4","execution":{"iopub.status.busy":"2022-04-17T09:13:46.950764Z","iopub.execute_input":"2022-04-17T09:13:46.950995Z","iopub.status.idle":"2022-04-17T09:13:46.958139Z","shell.execute_reply.started":"2022-04-17T09:13:46.950962Z","shell.execute_reply":"2022-04-17T09:13:46.957314Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Creating data indices for training and validation splits:\ndataset_size = len(train_data)\nindices = list(range(dataset_size))\nsplit = int(np.floor(validation_split * dataset_size))\n\nif shuffle_dataset :\n    np.random.seed(random_seed)\n    np.random.shuffle(indices)\n\ntrain_indices, val_indices = indices[split:], indices[:split]","metadata":{"id":"hMMT3ywFB1qw","execution":{"iopub.status.busy":"2022-04-17T09:13:46.959507Z","iopub.execute_input":"2022-04-17T09:13:46.960055Z","iopub.status.idle":"2022-04-17T09:13:46.967610Z","shell.execute_reply.started":"2022-04-17T09:13:46.960016Z","shell.execute_reply":"2022-04-17T09:13:46.966799Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_sampler = SubsetRandomSampler(train_indices)\nvalid_sampler = SubsetRandomSampler(val_indices)","metadata":{"id":"y04ehCdPB1qw","execution":{"iopub.status.busy":"2022-04-17T09:13:46.971544Z","iopub.execute_input":"2022-04-17T09:13:46.971804Z","iopub.status.idle":"2022-04-17T09:13:46.976858Z","shell.execute_reply.started":"2022-04-17T09:13:46.971770Z","shell.execute_reply":"2022-04-17T09:13:46.975545Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE,\n                                             sampler=train_sampler)\n\nvalid_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE,\n                                             sampler=valid_sampler)\n\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE)","metadata":{"id":"7lz7xjquB1qw","execution":{"iopub.status.busy":"2022-04-17T09:13:46.978762Z","iopub.execute_input":"2022-04-17T09:13:46.979109Z","iopub.status.idle":"2022-04-17T09:13:46.985116Z","shell.execute_reply.started":"2022-04-17T09:13:46.979071Z","shell.execute_reply":"2022-04-17T09:13:46.984350Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def test(model, data_loader):\n    \"\"\"Measures the accuracy of a model on a data set.\"\"\" \n    # Make sure the model is in evaluation mode.\n    model.eval()\n    # We do not need to maintain intermediate activations while testing.\n    accs = []\n    with torch.no_grad():\n        \n        # Loop over test data.\n        for features, target in data_loader:\n          \n            # Forward pass.\n            output = model(features.to(device))\n            \n            # Get the label corresponding to the highest predicted probability.\n            pred = output.argmax(dim=1, keepdim=True)\n            \n            # Count number of correct predictions.\n            correct = pred.cpu().eq(target.view_as(pred)).sum().item()\n            total = pred.shape[0]\n            accs.append(correct/total)\n\n    # Print test accuracy.\n    percent = 100. * np.mean(accs)\n    st = np.std(accs)\n    return percent, st\n\ndef train(model, criterion, data_loader, test_data_loader, optimizer, num_epochs, filename):\n    \"\"\"Simple training loop for a PyTorch model.\"\"\" \n    \n    # Make sure model is in training mode.\n    model.train()\n    \n    # Move model to the device (CPU or GPU).\n    model.to(device)\n    \n    # Exponential moving average of the loss.\n    ema_loss = None\n    \n    best_acc = 0\n\n    print('----- Training Loop -----')\n    # Loop over epochs.\n    for epoch in range(num_epochs):\n        \n        # Loop over data.\n        for batch_idx, (features, target) in enumerate(data_loader):\n\n            # Forward pass.\n            output = model(features.to(device))\n            loss = criterion(output.to(device), target.to(device))\n\n            # Backward pass.\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            # NOTE: It is important to call .item() on the loss before summing.\n            if ema_loss is None:\n                ema_loss = loss.item()\n            else:\n                ema_loss += (loss.item() - ema_loss) * 0.01 \n\n        # Print out progress the end of epoch.\n        print('----- Model Evaluation -----')\n        print('Epoch: {}/{} \\tTrain Loss: {:.6f}'.format(epoch+1,num_epochs, ema_loss))\n        train_a, train_st = test(model,data_loader)\n        test_a, test_st = test(model,test_data_loader)\n        print(f'Train accuracy: ({train_a:.2f}%) with std:({train_st:.2f})')\n        print(f'Test accuracy: ({test_a:.2f}%) with std:({test_st:.2f})')\n        if test_a > best_acc:\n            best_acc = test_a\n            torch.save(model.state_dict(), filename+\".pth\")\n            \n    checkpoint = torch.load(filename+\".pth\")\n    model.load_state_dict(checkpoint)\n    print(\"------\")\n    test_a, test_st = test(model,test_data_loader)\n    print(f'Final test accuracy: ({test_a:.2f}%) with std:({test_st:.2f})')\n    \n    return model\n    \n\ndef generate_predictions(model,data_loader):\n    model.eval()\n    preds=[]\n    idx=[]\n\n    print('----- MAKING PREDICTIONS -----')\n    # We do not need to maintain intermediate activations while testing.\n    with torch.no_grad():\n        \n        # Loop over test data.\n        for features, indices in data_loader:\n            \n            # Forward pass.\n            output = model(features.to(device))\n            \n            # Get the label corresponding to the highest predicted probability.\n            pred = output.argmax(dim=1, keepdim=True)\n            for p,ind in zip(pred,indices):\n                idx.append(ind)\n                preds.append(p.item())\n\n    return preds,idx\n\ndef map_to_classes(n):\n    return train_data.classes[n]","metadata":{"id":"jD6kZ_lEB1qx","execution":{"iopub.status.busy":"2022-04-17T09:13:46.986913Z","iopub.execute_input":"2022-04-17T09:13:46.987645Z","iopub.status.idle":"2022-04-17T09:13:47.008683Z","shell.execute_reply.started":"2022-04-17T09:13:46.987594Z","shell.execute_reply":"2022-04-17T09:13:47.007874Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def get_resnext(model_name):\n    model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n    model.avg_pool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n    model.last_linear = nn.Linear(in_features=2048, out_features=5, bias=True)#2048\n\n    criterion = torch.nn.CrossEntropyLoss()\n    optimizer = AdamHD(model.parameters(), lr=1e-4, hypergrad_lr=1e-9)\n\n    return model, criterion, optimizer\n\ndef get_eff_net(model_name, dim=1280):\n    model = EfficientNet.from_pretrained(model_name)\n    model._fc = nn.Linear(in_features=dim, out_features=5, bias=True)\n    \n    criterion = torch.nn.CrossEntropyLoss()\n    optimizer = AdamHD(model.parameters(), lr=1e-4, hypergrad_lr=1e-9)\n    \n    return model, criterion, optimizer","metadata":{"id":"pWwdEmQcB1qx","execution":{"iopub.status.busy":"2022-04-17T09:13:47.009879Z","iopub.execute_input":"2022-04-17T09:13:47.010112Z","iopub.status.idle":"2022-04-17T09:13:47.021864Z","shell.execute_reply.started":"2022-04-17T09:13:47.010087Z","shell.execute_reply":"2022-04-17T09:13:47.020989Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"preds = []","metadata":{"id":"lJsNchPSB1qx","execution":{"iopub.status.busy":"2022-04-17T09:13:47.023353Z","iopub.execute_input":"2022-04-17T09:13:47.023657Z","iopub.status.idle":"2022-04-17T09:13:47.031295Z","shell.execute_reply.started":"2022-04-17T09:13:47.023618Z","shell.execute_reply":"2022-04-17T09:13:47.030509Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model1, criterion, optimizer = get_resnext(MODEL_NAME1)\n#model1, criterion, optimizer =get_eff_net( MODEL_NAME2 , dim=1280)\nmodel1 = train(model1, criterion, train_loader, valid_loader, optimizer, num_epochs=NUM_EPOCHS1, filename=\"Resfin\")\n\ntta_model = tta.ClassificationTTAWrapper(model1, tta.aliases.five_crop_transform(DIM_TEST_2,DIM_TEST_2))\npredictions, _ = generate_predictions(tta_model,test_loader)\npreds.append(predictions)","metadata":{"id":"FJWrEuhzB1qy","outputId":"07f0adbe-a86b-4255-835d-514e3252eeb5","execution":{"iopub.status.busy":"2022-04-17T09:13:47.032586Z","iopub.execute_input":"2022-04-17T09:13:47.032900Z","iopub.status.idle":"2022-04-17T14:12:32.383521Z","shell.execute_reply.started":"2022-04-17T09:13:47.032861Z","shell.execute_reply":"2022-04-17T14:12:32.382673Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"final_predictions = np.mean(preds,axis=0)\nfinal_predictions.shape","metadata":{"id":"nLfpw482B1qy","execution":{"iopub.status.busy":"2022-04-17T14:12:32.384991Z","iopub.execute_input":"2022-04-17T14:12:32.385276Z","iopub.status.idle":"2022-04-17T14:12:32.393473Z","shell.execute_reply.started":"2022-04-17T14:12:32.385240Z","shell.execute_reply":"2022-04-17T14:12:32.392452Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"ss = pd.DataFrame({\n    \"Category\": final_predictions,\n    \"Id\": test_data.indices\n})\nss.head()","metadata":{"id":"vIT4aOQkB1qy","execution":{"iopub.status.busy":"2022-04-17T14:12:32.395015Z","iopub.execute_input":"2022-04-17T14:12:32.395864Z","iopub.status.idle":"2022-04-17T14:12:32.418047Z","shell.execute_reply.started":"2022-04-17T14:12:32.395819Z","shell.execute_reply":"2022-04-17T14:12:32.417175Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"ss[\"Category\"] = predictions\nss[\"Category\"] = ss[\"Category\"].apply(map_to_classes)\nss.head()","metadata":{"id":"qwfSLbJAB1qy","execution":{"iopub.status.busy":"2022-04-17T14:12:32.419348Z","iopub.execute_input":"2022-04-17T14:12:32.420139Z","iopub.status.idle":"2022-04-17T14:12:32.437055Z","shell.execute_reply.started":"2022-04-17T14:12:32.420098Z","shell.execute_reply":"2022-04-17T14:12:32.436342Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"NAME=\"FinalSUbm\"","metadata":{"execution":{"iopub.status.busy":"2022-04-17T14:12:32.439095Z","iopub.execute_input":"2022-04-17T14:12:32.439541Z","iopub.status.idle":"2022-04-17T14:12:32.444744Z","shell.execute_reply.started":"2022-04-17T14:12:32.439503Z","shell.execute_reply":"2022-04-17T14:12:32.443845Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"ss.to_csv(NAME+\".csv\",index=False)","metadata":{"id":"bLVCyy43B1qy","execution":{"iopub.status.busy":"2022-04-17T14:12:32.446571Z","iopub.execute_input":"2022-04-17T14:12:32.447112Z","iopub.status.idle":"2022-04-17T14:12:32.466021Z","shell.execute_reply.started":"2022-04-17T14:12:32.447073Z","shell.execute_reply":"2022-04-17T14:12:32.465324Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"P7s1Z6gzB1qy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}